{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-16T09:22:44.524698Z",
     "start_time": "2025-05-16T09:22:43.869188Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/domains-and-seqs-merged.csv\")\n"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T09:22:45.283492Z",
     "start_time": "2025-05-16T09:22:44.930664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df[\"homology_path\"] = df[\"class\"].astype(str) + \".\" + \\\n",
    "                  df[\"architecture\"].astype(str) + \".\" + \\\n",
    "                  df[\"topology\"].astype(str) + \".\" + \\\n",
    "                  df[\"homology\"].astype(str)\n"
   ],
   "id": "9cf7f6cdd65a43a2",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T09:22:56.827084Z",
     "start_time": "2025-05-16T09:22:55.539792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "MIN_DOMAINS_PER_HOMOLOGY = 10\n",
    "MAX_DOMAINS_PER_HOMOLOGY = 200\n",
    "\n",
    "HOMOLOGY_GROUPS = 100\n",
    "SAMPLES_PER_GROUP = 10\n",
    "\n",
    "# Define hierarchy columns â€” this full path defines a unique homology group\n",
    "hierarchy = ['class', 'architecture', 'topology', 'homology']\n",
    "\n",
    "# Drop duplicates by s35 within each homology group\n",
    "# First, create a groupby object on hierarchy columns\n",
    "grouped = df.groupby(hierarchy)\n",
    "\n",
    "# Apply drop_duplicates on 's35' to each group and collect results\n",
    "unique_s35_per_group = []\n",
    "for name, group in grouped:\n",
    "    # Drop duplicates by s35 within this specific homology group\n",
    "    unique_s35 = group.drop_duplicates('s35')\n",
    "    unique_s35_per_group.append(unique_s35)\n",
    "\n",
    "# Combine all dataframes with unique s35 values per homology group\n",
    "df_unique_s35 = pd.concat(unique_s35_per_group)\n",
    "\n",
    "# Step 1 & 2: Filter groups where the number of domain_id entries is at least 10 and at most 200\n",
    "filtered_df = df_unique_s35.groupby(hierarchy).filter(lambda x: MIN_DOMAINS_PER_HOMOLOGY <= len(x) <= MAX_DOMAINS_PER_HOMOLOGY)\n",
    "\n",
    "# Step 3: Get unique full-path homology groups\n",
    "unique_homology_paths = filtered_df[hierarchy].drop_duplicates()\n",
    "\n",
    "# Randomly sample 100 unique homology groups (based on full path)\n",
    "sampled_paths = unique_homology_paths.sample(n=min(HOMOLOGY_GROUPS, len(unique_homology_paths)), random_state=42)\n",
    "\n",
    "# Step 4: Retain only rows that belong to the sampled groups\n",
    "sampled_df = pd.merge(sampled_paths, filtered_df, on=hierarchy)\n",
    "\n",
    "# Within each sampled group, randomly choose 10 domain_id entries\n",
    "subset = sampled_df.groupby(hierarchy).apply(lambda x: x.sample(n=min(SAMPLES_PER_GROUP, len(x)), random_state=42)).reset_index(drop=True)\n",
    "\n",
    "# Save to CSV\n",
    "subset.to_csv(\"../data/subset.csv\", index=False)"
   ],
   "id": "eebda538a6f803d9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6p/_m5tm17x05qfp8tftlrxjzd00000gn/T/ipykernel_6150/2053432599.py:39: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  subset = sampled_df.groupby(hierarchy).apply(lambda x: x.sample(n=min(SAMPLES_PER_GROUP, len(x)), random_state=42)).reset_index(drop=True)\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T15:47:42.454452Z",
     "start_time": "2025-05-12T15:47:19.324074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5EncoderModel\n",
    "\n",
    "# Load ProtT5 model and tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", do_lower_case=False)\n",
    "model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\")\n",
    "model = model.eval()\n",
    "\n",
    "# Check if CUDA is available and set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ],
   "id": "790dd24eb634af3a",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T16:05:44.801567Z",
     "start_time": "2025-05-12T16:05:30.922912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dictionary to store embeddings\n",
    "all_embeddings = {}\n",
    "\n",
    "# Process each sequence\n",
    "for index, row in subset.head(50).iterrows():\n",
    "    sequence = row[\"sequence\"]\n",
    "    sequence = sequence.replace('U', 'X').replace('Z', 'X').replace('O', 'X')\n",
    "    ids = tokenizer.batch_encode_plus([sequence], add_special_tokens=True, padding=True, return_tensors=\"pt\")\n",
    "    input_ids = ids['input_ids'].to(device)\n",
    "    attention_mask = ids['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        embedding = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Average over tokens to get a single vector per sequence\n",
    "    sequence_embedding = embedding.last_hidden_state.mean(dim=1).squeeze().cpu()\n",
    "\n",
    "    # Store in dictionary\n",
    "    all_embeddings[index] = sequence_embedding\n",
    "\n",
    "    print(f\"Processed: {index}\")\n",
    "\n",
    "# Save all embeddings to one file\n",
    "torch.save(all_embeddings, \"../data/all_embeddings.pt\")\n",
    "print(\"All embeddings saved to all_embeddings.pt\")\n"
   ],
   "id": "f38bc03943fdc6cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 0\n",
      "Processed: 1\n",
      "Processed: 2\n",
      "Processed: 3\n",
      "Processed: 4\n",
      "Processed: 5\n",
      "Processed: 6\n",
      "Processed: 7\n",
      "Processed: 8\n",
      "Processed: 9\n",
      "Processed: 10\n",
      "Processed: 11\n",
      "Processed: 12\n",
      "Processed: 13\n",
      "Processed: 14\n",
      "Processed: 15\n",
      "Processed: 16\n",
      "Processed: 17\n",
      "Processed: 18\n",
      "Processed: 19\n",
      "Processed: 20\n",
      "Processed: 21\n",
      "Processed: 22\n",
      "Processed: 23\n",
      "Processed: 24\n",
      "Processed: 25\n",
      "Processed: 26\n",
      "Processed: 27\n",
      "Processed: 28\n",
      "Processed: 29\n",
      "Processed: 30\n",
      "Processed: 31\n",
      "Processed: 32\n",
      "Processed: 33\n",
      "Processed: 34\n",
      "Processed: 35\n",
      "Processed: 36\n",
      "Processed: 37\n",
      "Processed: 38\n",
      "Processed: 39\n",
      "Processed: 40\n",
      "Processed: 41\n",
      "Processed: 42\n",
      "Processed: 43\n",
      "Processed: 44\n",
      "Processed: 45\n",
      "Processed: 46\n",
      "Processed: 47\n",
      "Processed: 48\n",
      "Processed: 49\n",
      "All embeddings saved to all_embeddings.pt\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### Would you recommend to cluster by s35 to avoid overlaps\n",
    "### Should we trim / pick equally sized seqs lengths / How should we pad\n",
    "### "
   ],
   "id": "4774b13e968a8152"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
